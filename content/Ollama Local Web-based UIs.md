---
title: Ollama Local Web-based UIs
date: 2024-04-20
description: It analyzes different UI apps built on Ollama
tags:
  - AI
  - Ollama
  - UI
aliases: 
draft: true
---
# Introduction
I love using Ollama time-to-time on my local machine. I mostly use it in my Obsidian vault for academic purposes such as paraphrasing, language translation, and so on…


[big-AGI]()
I am using the big-AGI couple of times. Somehow it doesn’t fit my needs in terms of UI. There some irrelevant features that doesn’t make sense. 

[Open Web UI](https://github.com/open-webui/open-webui)
Similar to [big-AGI]()


# Code Helper
[Llama Coder](https://github.com/ex3ndr/llama-coder) alternative to Copilot
[Tabby](https://tabby.tabbyml.com/docs/getting-started) Alternative code helper works with VS Code
# Obsidian Plug-ins
[Obsidian Ollama](https://github.com/hinterdupfinger/obsidian-ollama) allows to send instruction to Ollama using Obsidian. You can set your own prompts customized for specific tasks.

[Local GPT](https://github.com/pfrankov/obsidian-local-gpt) is similar to [Obsidian Ollama](https://github.com/hinterdupfinger/obsidian-ollama), plus you can use any OpenAI compatible server other than Ollama.